# shellcheck shell=dash
# In this version, we just provide advise and chat ... No llmf integration.
___x_cmd log init lms
xrc:mod:lib     lms     cfg     chat/_index

___X_CMD_LMS_DEFAULT_ENDPOINT="http://localhost:1234"
___x_cmd_lms___main(){
    [ "$#" -gt 0 ] ||   set -- --help

    local op="$1"; shift
    case "$op" in
        # llmf|load)

        #             ;;
        chat)           ___x_cmd_lms_chat       "$@"    ;;
        init|--init)    ___x_cmd_lms_init       "$@"    ;;
        --cur|--cfg)    ___x_cmd_lms_"${op#--}" "$@"    ;;
        *)              ___x_cmd_lms___cmd "$op" "$@"   ;;
    esac
}

# Introduce @lms

___x_cmd_lms___cmd(){
    local x_=""

    if ___x_cmd_hascmd lms; then
        command lms "$@"
    elif ___x_cmd_lms___cmd_fp_; then
        lms:debug "Original cmd path => $x_"
        "$x_" "$@"
    else
        lms:error "Please install LM Studio from official website -> https://lmstudio.ai/"
        return 1
    fi
}

___x_cmd_lms___cmd_fp_(){
    x_=""

    [ -z "$___X_CMD_LMS_ORIGIN_CMD_FP" ] || {
        x_="$___X_CMD_LMS_ORIGIN_CMD_FP"
        return 0
    }

    if [ -x "$HOME/.cache/lm-studio/bin/lms" ]; then
        x_="$HOME/.cache/lm-studio/bin/lms"
    elif [ -x "$HOME/.cache/lm-studio/bin/lms.exe" ]; then
        x_="$HOME/.cache/lm-studio/bin/lms.exe"
    elif ___x_cmd os is wsl; then
        x_="$( ___x_cmd pwsh -Command Write-Host \$env:USERPROFILE )"
        ___x_cmd pwsh path win_to_linux_ "$x_"
        x_="${x_}/.cache/lm-studio/bin/lms.exe"
        [ -x "$x_" ] || return 1
    fi

    [ -n "$x_" ] || return
    ___X_CMD_LMS_ORIGIN_CMD_FP="$x_"
}
