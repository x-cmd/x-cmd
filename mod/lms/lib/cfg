# shellcheck shell=dash disable=SC2034

xrc cfgy
___x_cmd_lms_cfg(){
    [ "$#" -gt 0 ] || {
        ___x_cmd_lms_init
        return
    }

    local op="$1"; shift
    case "$op" in
        -h|--help)      ___x_cmd help -m lms --cfg ;;
        *)              ___x_cmd_lms_cfg___invoke "$op" "$@" ;;
    esac
}

___x_cmd_lms_cur(){
    local X_help_cmd=; X_help_cmd='___x_cmd help -m lms --cur' help:arg:parse
    ___x_cmd_lms_cfg --current "$@"
}

___x_cmd_lms_init(){
    local cur_model=; local cur_maxtoken=; local cur_temperature=; local cur_port=;

    if [ -f "$(___x_cmd_lms_cur --get config)" ]; then
        ___x_cmd_lms_cur cur_model:=model cur_maxtoken:=maxtoken cur_temperature:=temperature cur_endpoint:=endpoint 2>/dev/null
    fi

    ___x_cmd_lms_cfg___invoke --init ${cur_model:+"--ctrl_exit_strategy"} \
        model       "Set up the LM Studio AI model"                     \
                    "${cur_model}"              '='                 --  \
        maxtoken    "Set up the LM Studio AI maxtoken"                  \
                    "${cur_maxtoken:-"-1"}" -- \
        temperature "Set up the LM Studio AI temperature"               \
                    "${cur_temperature:-"0.7"}"                     --  \
        endpoint    "Set up the endpoint (optional)"                    \
                    "${cur_endpoint:-"$___X_CMD_LMS_DEFAULT_ENDPOINT"}"
}

___X_CMD_LMS_CFG_VARLIST="model,maxtoken,temperature,seed,endpoint"
___x_cmd_lms_cfg___invoke(){
    ___x_cmd_cfgy_obj                                               \
        --prefix            ___X_CMD_LMS_CFG_DATA                \
        --default-config    "${___X_CMD_ROOT_CFG}/lms/X.cfg.yml" \
        --current-config    "${___X_CMD_LMS_LOCAL_CONFIG}"       \
        --current-profile   "${___X_CMD_LMS_LOCAL_PROFILE}"      \
        --varlist           "$___X_CMD_LMS_CFG_VARLIST"          \
        "$@"
}

