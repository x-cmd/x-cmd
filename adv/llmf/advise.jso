{
"#name"
:
{
"llmf"
:
null
}
,
"#desc"
:
{
"en"
:
"Run the local model"
,
"cn"
:
"运行本地模型"
}
,
"#tip"
:
[
{
"en"
:
"Use `@l` to chat via API in terminal. Make sure the model is loaded with `x llmf serve --nobrowser` first."
,
"cn"
:
"使用 `@l` 在终端中通过 API 进行聊天。请先使用 `x llmf serve --nobrowser` 加载模型。"
}
]
,
"#keyword"
:
[
"llmf"
,
"local llm"
,
"llamafile"
,
"llama.cpp"
]
,
"#tldr"
:
[
{
"cmd"
:
"x llmf cli -p 'write a story about llamafile'"
,
"en"
:
"Use the command line mode to output a story about llamafile"
,
"cn"
:
"使用命令行模式输出一个关于 llamafile 的故事"
}
,
{
"cmd"
:
"x llmf model ls"
,
"en"
:
"List all downloadable models"
,
"cn"
:
"列出所有可下载模型"
}
]
,
"chat"
:
{
"#desc"
:
{
"cn"
:
"与 llmf 对话"
,
"en"
:
"chat with llmf"
}
,
"request"
:
{
"#desc"
:
{
"cn"
:
"发起请求"
,
"en"
:
"send a request"
}
,
"$ref"
:
"x-advise://chat/data/exec.jso"
}
}
,
"serve"
:
{
"#desc"
:
{
"en"
:
"Use the server mode"
,
"cn"
:
"使用服务器模式"
}
,
"-m|--model"
:
{
"#synopsis"
:
"<FPATH>"
,
"#desc"
:
{
"en"
:
"Model path in the GGUF file format"
,
"cn"
:
"GGUF 文件格式中的模型路径"
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"模型名称"
,
"cn"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_model"
}
}
,
"--mmproj"
:
{
"#synopsis"
:
"<FPATH>"
,
"#desc"
:
{
"en"
:
"Specifies path of the LLaVA vision model in the GGUF file format"
,
"cn"
:
"指定 LLAVA 视觉模型的路径，格式为 GGUF 文件"
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"模型名称"
,
"cn"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_mmproj"
}
}
,
"--port"
:
{
"#synopsis"
:
"<PORT>"
,
"#desc"
:
{
"en"
:
"Port to listen"
,
"cn"
:
"监听的端口"
}
,
"#1"
:
null
}
,
"--host"
:
{
"#synopsis"
:
"<IPADDR>"
,
"#desc"
:
{
"en"
:
"IP address to listen"
,
"cn"
:
"监听的 IP 地址"
}
,
"#1"
:
null
}
,
"--"
:
{
"#subcmd"
:
true
,
"#desc"
:
{
"en"
:
"Use the arguments of the native llamafile command"
,
"cn"
:
"使用原生 llamafile 命令的参数"
}
,
"#n"
:
{
"#desc"
:
{
"en"
:
"Arguments for llamafile --server"
,
"cn"
:
"llamafile --server 的参数"
}
,
"$ref"
:
"x-cmd-advise://llamafile/data/server/advise.t.jso"
}
}
,
"getembedding"
:
{
"#desc"
:
{
"en"
:
"Generating text vector data"
,
"cn"
:
"生成文本向量数据"
}
,
"-f|--file"
:
{
"#desc"
:
{
"en"
:
"text file"
,
"cn"
:
"文本文件"
}
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"string"
,
"cn"
:
"字符串"
}
}
}
}
,
"cli"
:
{
"#desc"
:
{
"en"
:
"Use the command line interface mode"
,
"cn"
:
"使用命令行界面模式"
}
,
"-m|--model"
:
{
"#synopsis"
:
"<FPATH>"
,
"#desc"
:
{
"en"
:
"Model path in the GGUF file format"
,
"cn"
:
"GGUF 文件格式中的模型路径"
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"模型名称"
,
"cn"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_model"
}
}
,
"--mmproj"
:
{
"#synopsis"
:
"<FPATH>"
,
"#desc"
:
{
"en"
:
"Specifies path of the LLaVA vision model in the GGUF file format"
,
"cn"
:
"指定 LLAVA 视觉模型的路径，格式为 GGUF 文件"
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"模型名称"
,
"cn"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_mmproj"
}
}
,
"-p|--prompt"
:
{
"#synopsis"
:
"<STRING>"
,
"#desc"
:
{
"en"
:
"Prompt to start text generation"
,
"cn"
:
"开始文本生成的提示"
}
,
"#1"
:
null
}
,
"--stdin"
:
{
"#desc"
:
{
"en"
:
"Read the prompt from the stdin"
,
"cn"
:
"从 stdin 中读取 prompt"
}
}
,
"-t|--temp"
:
{
"#synopsis"
:
"<N>"
,
"#desc"
:
{
"en"
:
"Temperature"
,
"cn"
:
"温度"
}
,
"#1"
:
null
}
,
"-0"
:
{
"#desc"
:
{
"en"
:
"The temperature is set to 0"
,
"cn"
:
"温度设置为0"
}
}
,
"-|--edit"
:
{
"#desc"
:
{
"en"
:
"Edit the prompt before running"
,
"cn"
:
"运行前编辑 prompt"
}
}
,
"--"
:
{
"#subcmd"
:
true
,
"#desc"
:
{
"en"
:
"Use the arguments of the native llamafile command"
,
"cn"
:
"使用原生 llamafile 命令的参数"
}
,
"#n"
:
{
"#desc"
:
{
"en"
:
"Arguments for llamafile --cli"
,
"cn"
:
"llamafile --cli 的参数"
}
,
"$ref"
:
"x-cmd-advise://llamafile/data/cli/advise.t.jso"
}
}
}
,
"model"
:
{
"#desc"
:
{
"en"
:
"Manage local models"
,
"cn"
:
"管理本地模型"
}
,
"#tldr"
:
[
{
"cmd"
:
"x llmf model ls --local"
,
"en"
:
"View local downloaded models"
,
"cn"
:
"查看本地下载的模型"
}
,
{
"cmd"
:
"x llmf model which <model name>"
,
"en"
:
"Query model storage location"
,
"cn"
:
"查询模型存储位置"
}
]
,
"default"
:
{
"#desc"
:
{
"en"
:
"Manage default models"
,
"cn"
:
"管理默认模型"
}
,
"get"
:
{
"#desc"
:
{
"en"
:
"Get default models"
,
"cn"
:
"查看默认模型"
}
}
,
"set"
:
{
"#desc"
:
{
"en"
:
"Set default models"
,
"cn"
:
"设置默认模型"
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"模型名称"
,
"cn"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_model; ___x_cmd_llmf_advise___ls_mmproj"
}
}
}
,
"ls"
:
{
"#desc"
:
{
"en"
:
"Lists locally downloaded models"
,
"cn"
:
"罗列本地已下载的模型"
}
,
"#cand"
:
[
{
"-j|--json"
:
{
"#desc"
:
{
"en"
:
"output raw JSON data"
,
"cn"
:
"以 JSON 格式输出获取数据"
}
}
}
,
{
"--csv"
:
{
"#desc"
:
{
"en"
:
"output raw CSV data"
,
"cn"
:
"以 CSV 格式输出获取数据"
}
}
}
,
{
"--app"
:
{
"#desc"
:
{
"en"
:
"Output with interactive TUI"
,
"cn"
:
"交互式 TUI 输出"
}
}
}
]
}
,
"la"
:
{
"#desc"
:
{
"en"
:
"Use the interactive UI to list all downloadable models"
,
"cn"
:
"使用交互式 UI 列出所有可下载模型"
}
,
"#cand"
:
[
{
"-j|--json"
:
{
"#desc"
:
{
"en"
:
"output raw JSON data"
,
"cn"
:
"以 JSON 格式输出获取数据"
}
}
}
,
{
"--csv"
:
{
"#desc"
:
{
"en"
:
"output raw CSV data"
,
"cn"
:
"以 CSV 格式输出获取数据"
}
}
}
,
{
"--app"
:
{
"#desc"
:
{
"en"
:
"Output with interactive TUI"
,
"cn"
:
"交互式 TUI 输出"
}
}
}
]
}
,
"info"
:
{
"#desc"
:
{
"en"
:
"Get model information"
,
"cn"
:
"查看模型信息"
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"模型名称"
,
"cn"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_model; ___x_cmd_llmf_advise___ls_mmproj"
}
}
,
"which"
:
{
"#desc"
:
{
"en"
:
"Query model storage location"
,
"cn"
:
"查询模型存储位置"
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"模型名称"
,
"cn"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_model_local"
}
}
,
"download"
:
{
"#desc"
:
{
"en"
:
"Download specified model"
,
"cn"
:
"下载指定模型"
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"模型名称"
,
"cn"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_model; ___x_cmd_llmf_advise___ls_mmproj"
}
}
,
"export"
:
{
"#desc"
:
{
"cn"
:
"导出本地模型"
,
"en"
:
"Export local model"
}
,
"#1"
:
{
"#desc"
:
{
"cn"
:
"模型名称"
,
"en"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_model_local"
}
,
"#2"
:
{
"#desc"
:
{
"cn"
:
"目标目录"
,
"en"
:
"target directory"
}
,
"#exec"
:
"___x_cmd_advise__dir"
}
,
"#tldr"
:
[
{
"cmd"
:
"x llmf model export llava/llama-3-8b-v1_1/int4.gguf path/to/target_directory"
,
"cn"
:
"将本地 llava/llama-3-8b-v1_1/int4.gguf 模型导出到目标目录里面"
,
"en"
:
"Export llava/llama-3-8b-v1_1/int4.gguf to target directory"
}
]
}
,
"import"
:
{
"#desc"
:
{
"cn"
:
"导入本地模型"
,
"en"
:
"Import local model"
}
,
"#1"
:
{
"#desc"
:
{
"cn"
:
"源文件"
,
"en"
:
"source file"
}
,
"#exec"
:
"___x_cmd_advise__file"
}
,
"#2"
:
{
"#desc"
:
{
"cn"
:
"模型名称"
,
"en"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_model; ___x_cmd_llmf_advise___ls_mmproj"
}
,
"#tldr"
:
[
{
"cmd"
:
"x llmf model import path/to/source_file llava/llama-3-8b-v1_1/int4.gguf"
,
"cn"
:
"将源文件导入为本地 llava/llama-3-8b-v1_1/int4.gguf 模型"
,
"en"
:
"Import source file as llava/llama-3-8b-v1_1/int4.gguf"
}
]
}
,
"remove"
:
{
"#desc"
:
{
"cn"
:
"删除本地已存在的模型"
,
"en"
:
"Remove local existing model"
}
,
"#1"
:
{
"#desc"
:
{
"cn"
:
"模型名称"
,
"en"
:
"model name"
}
,
"#exec:stdout"
:
"xrc llmf; ___x_cmd_llmf_advise___ls_model_local"
}
}
}
,
"tokenize"
:
{
"#desc"
:
{
"cn"
:
"文本分词"
,
"en"
:
"text segmentation"
}
}
,
"init"
:
{
"#subcmd"
:
true
,
"#desc"
:
{
"en"
:
"Initialize the configuration using interactive mode"
,
"cn"
:
"使用交互模式初始化配置"
}
}
,
"--cfg"
:
{
"#subcmd"
:
true
,
"#desc"
:
{
"cn"
:
"配置管理"
,
"en"
:
"Manage config item"
}
,
"clear"
:
{
"#desc"
:
{
"en"
:
"Clear all setting default in the current session and reback the default value of the config record"
,
"cn"
:
"清除当前会话设置的默认值, 恢复为配置记录默认值"
}
}
,
"cat"
:
{
"#desc"
:
{
"en"
:
"List all current value in the session"
,
"cn"
:
"获取当前会话设置的所有默认值"
}
}
,
"#n"
:
{
"#cand"
:
[
{
"model="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"model choose"
,
"cn"
:
"模型选择"
}
}
}
,
{
"endpoint="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"Set an endpoint"
,
"cn"
:
"设置 endpoint 信息的值"
}
}
}
]
}
}
,
"--cur"
:
{
"#subcmd"
:
true
,
"#desc"
:
{
"en"
:
"current session default value management"
,
"cn"
:
"当前会话默认值管理"
}
,
"set"
:
{
"#desc"
:
{
"en"
:
"Setting openai config"
,
"cn"
:
"设置 openai 配置"
}
,
"model="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"model choose"
,
"cn"
:
"模型选择"
}
}
,
"endpoint="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"Set an endpoint"
,
"cn"
:
"设置 endpoint 信息的值"
}
}
,
"#n"
:
{
"#cand"
:
[
{
"model="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"模型选择"
,
"cn"
:
"model choose"
}
}
}
,
{
"endpoint="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"Set an endpoint"
,
"cn"
:
"设置 endpoint 信息的值"
}
}
}
]
}
}
}
,
"#other"
:
{
"en"
:
{
"Please visit our homepage for more information:"
:
"https://x-cmd.com/mod/llmf"
}
,
"cn"
:
{
"请访问我们的主页以获取更多信息："
:
"https://x-cmd.com/mod/llmf"
}
}
}

