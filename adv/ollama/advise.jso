{
"#name"
:
{
"ollama"
:
null
,
"cn"
:
"本地部署大型语言模型的开源框架 ollama 的命令行客户端工具"
,
"en"
:
"The command-line client tool for Ollama, an open-source framework for running large language models locally."
}
,
"#keyword"
:
[
"ollama AI cli"
,
"local LLM"
,
"open-source LLM"
]
,
"init"
:
{
"#subcmd"
:
true
,
"#desc"
:
{
"en"
:
"Initialize the configuration using interactive mode"
,
"cn"
:
"使用交互模式初始化配置"
}
}
,
"--cfg|cfg"
:
{
"#subcmd"
:
true
,
"#desc"
:
{
"cn"
:
"配置选项"
,
"en"
:
"Manage config of model"
}
,
"cat"
:
{
"#desc"
:
{
"cn"
:
"输出配置项"
,
"en"
:
"Output config item"
}
}
,
"temperature="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"cn"
:
"设置 gemini AI 生成文本的随机性"
,
"en"
:
"Setting the Randomness of Ollama AI Text Generation"
}
}
,
"endpoint="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"Set the endpoint of Ollama, not necessary"
,
"cn"
:
"设置 Ollama 的通信终点，非必需"
}
}
,
"ctx="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"Set max text number, not necessary"
,
"cn"
:
"最大文本值，非必需"
}
}
,
"set"
:
{
"#desc"
:
{
"en"
:
"Setting ollama config"
,
"cn"
:
"设置 ollama 配置"
}
,
"temperature="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"cn"
:
"设置 gemini AI 生成文本的随机性"
,
"en"
:
"Setting the Randomness of Ollama AI Text Generation"
}
}
,
"endpoint="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"Set the endpoint of Ollama, not necessary"
,
"cn"
:
"设置 Ollama 的通信终点，非必需"
}
}
,
"ctx="
:
{
"#nospace"
:
true
,
"#desc"
:
{
"en"
:
"Set max text number, not necessary"
,
"cn"
:
"最大文本值，非必需"
}
}
}
}
,
"chat"
:
{
"#desc"
:
{
"cn"
:
"与模型对话"
,
"en"
:
"chat with model"
}
,
"request"
:
{
"#desc"
:
{
"cn"
:
"发起请求"
,
"en"
:
"send a request"
}
,
"$ref"
:
"x-advise://chat/data/exec.jso"
}
}
,
"install"
:
{
"#desc"
:
{
"en"
:
"Install ollama"
,
"cn"
:
"安装 ollama"
}
}
,
"uninstall"
:
{
"#desc"
:
{
"en"
:
"Uninstall ollama"
,
"cn"
:
"卸载 ollama"
}
}
,
"serve"
:
{
"#desc"
:
{
"en"
:
"Start ollama"
,
"cn"
:
"启动 ollama"
}
}
,
"create"
:
{
"#desc"
:
{
"en"
:
"Create a model from a Modelfile"
,
"cn"
:
"从 Modelfile 创建模型"
}
}
,
"la"
:
{
"#desc"
:
{
"en"
:
"Interactive UI for viewing and manage remote models"
,
"cn"
:
"交互式 UI 查看和下载远程模型"
}
}
,
"show"
:
{
"#desc"
:
{
"en"
:
"Show information for a model"
,
"cn"
:
"显示模型信息"
}
,
"#exec:stdout"
:
"___x_cmd_ollama_advise_model_ls_loaded"
}
,
"run"
:
{
"#desc"
:
{
"en"
:
"Run a model"
,
"cn"
:
"运行模型"
}
,
"#exec:stdout"
:
"___x_cmd_ollama_advise_model_ls_loaded"
}
,
"pull"
:
{
"#desc"
:
{
"en"
:
"Pull a model from a registry"
,
"cn"
:
"从注册表拉取模型"
}
}
,
"push"
:
{
"#desc"
:
{
"en"
:
"Push a model to a registry"
,
"cn"
:
"推送模型到注册表"
}
}
,
"help"
:
{
"#desc"
:
{
"en"
:
"Help about any command"
,
"cn"
:
"帮助"
}
}
,
"--help|-h"
:
{
"#desc"
:
{
"en"
:
"help for ollama"
,
"cn"
:
"ollama 帮助"
}
}
,
"--version|-v"
:
{
"#desc"
:
{
"en"
:
"Show version information"
,
"cn"
:
"显示版本信息"
}
}
,
"ls"
:
{
"#desc"
:
{
"en"
:
"View locally downloaded models"
,
"cn"
:
"查看本地已下载的模型"
}
}
,
"cp"
:
{
"#desc"
:
{
"en"
:
"Copy a model"
,
"cn"
:
"复制模型"
}
}
,
"rm"
:
{
"#desc"
:
{
"en"
:
"Remove a model"
,
"cn"
:
"移除模型"
}
,
"#1"
:
{
"#desc"
:
{
"en"
:
"Model name"
,
"cn"
:
"模型的名字"
}
,
"#exec:stdout"
:
"___x_cmd_ollama_advise_model_ls_loaded"
}
}
,
"#subcmd:Enhance"
:
[
"chat"
,
"init"
,
"--cfg|cfg"
,
"install"
,
"uninstall"
,
"la"
,
"ls"
]
,
"#tldr"
:
[
{
"cmd"
:
"x ollama la"
,
"cn"
:
"交互式 UI 查看和下载远程模型"
,
"en"
:
"Interactive UI to view and download remote models"
}
,
{
"cmd"
:
"x ollama ls"
,
"cn"
:
"查看本地已下载的模型"
,
"en"
:
"View locally downloaded models"
}
,
{
"cmd"
:
"@o --file ./abstract.cn.md --file ./content.cn.md Translate to chinese"
,
"cn"
:
"把文件内容翻译为中文 （使用 alias 的方式）"
,
"en"
:
"Translate the file content into Chinese (using alias)"
}
,
{
"cmd"
:
"x wkp extract CentOS | @o"
,
"cn"
:
"基于 CentOS 的维基百科内容进行聊天"
,
"en"
:
"Chatting based on Wikipedia content on CentOS"
}
,
{
"cmd"
:
"x ollama chat request --file ./abstract.cn.md --file ./content.cn.md Translate to chinese"
,
"cn"
:
"把文件内容翻译为中文"
,
"en"
:
"Translate the content of the file into Chinese"
}
,
{
"cmd"
:
"x ollama install"
,
"cn"
:
"安装 ollama"
,
"en"
:
"Install ollama"
}
,
{
"cmd"
:
"x ollama pull mistral"
,
"cn"
:
"下载 mistral 模型"
,
"en"
:
"Download mistral model"
}
]
}

